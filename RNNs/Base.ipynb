{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch as th \n",
    "# import torch.nn as nn \n",
    "# import torch.nn.functional as F\n",
    "# from torch.optim import Adam\n",
    "# from torch.utils.data import DataLoader, Dataset, random_split \n",
    "\n",
    "# import lightning as L\n",
    "# from lightning import LightningModule, Trainer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# embeddings_dict = {}\n",
    "# with open(r\"/Users/suyashsachdeva/Desktop/glove/glove.6B.50d.txt\", 'r') as f:\n",
    "#     for line in f:\n",
    "#         values = line.split()\n",
    "#         word = values[0]\n",
    "#         vector = np.asarray(values[1:], \"float32\")\n",
    "#         embeddings_dict[word] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "# lemmatizer = WordNetLemmatizer()\n",
    "# file = r'/Users/suyashsachdeva/Desktop/dialogs.txt'\n",
    "# file = open(file, \"r\")\n",
    "\n",
    "# def sentences(sent):\n",
    "#         return [embeddings_dict[lemmatizer.lemmatize(''.join(e for e in word if e.isalnum()).lower())] for word in sent.split(\" \")]\n",
    "\n",
    "# # dataset = [[[embeddings_dict[lemmatizer.lemmatize(''.join(e for e in word if e.isalnum()).lower())] for word in sentence.split(\"\\t\")[0].split(\" \")], [embeddings_dict[lemmatizer.lemmatize(''.join(e for e in word if e.isalnum()).lower())] for word in sentence.split(\"\\t\")[1].split(\" \")]] for sentence in file.read().split(\"\\n\")]\n",
    "# # dataset\n",
    "# dataset = []\n",
    "# for sent in file.read().replace(\"'ll\", \" will\").replace(\"'ve\", \" have\").replace(\"n't\", \" not\").replace(\"101-98\", \"one zero one to nine eight\").replace(\",000\", \" thousand\").replace(\"-\", \" \").split(\"\\n\"):\n",
    "#     print(sent)\n",
    "#     [inp, out] = sent.split(\"\\t\")\n",
    "#     inp = sentences(inp.strip())\n",
    "#     out = sentences(out.strip())\n",
    "#     dataset.append([inp, out])\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "from torch.optim import Adam \n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import lightning as L \n",
    "from lightning import Trainer, LightningModule\n",
    "\n",
    "import torchtext as thtxt \n",
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "from torchtext.vocab import FastText\n",
    "\n",
    "import os \n",
    "import re \n",
    "import numpy as np\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taka_tak_question(sentence):\n",
    "    sentence = [\"<sos>\"] + [x for x in nlp(sentence)] + [\"<eos>\"]\n",
    "    return [\"<pad>\"]*(25 - len(sentence)) + sentence\n",
    "\n",
    "def taka_tak_answer(sentence):\n",
    "    sentence = [\"<sos>\"] + [x for x in nlp(sentence)] + [\"<eos>\"]\n",
    "    return  sentence + [\"<pad>\"]*(25 - len(sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "question = Field(sequential=True, use_vocab=False, include_lengths=True, tokenize=taka_tak_question, pad_first=True,  pad_token=\"<pad>\", batch_first=True, fix_length=22)#, preprocessing=embedded)\n",
    "answer   = Field(sequential=True, use_vocab=False, include_lengths=True,tokenize=taka_tak_answer, pad_first=False, pad_token=\"<pad>\", batch_first=True, fix_length=22)#, preprocessing=embedded)\n",
    "\n",
    "fields = {\"question\": (\"q\", question), \"answer\": (\"a\", answer)}\n",
    "traindata, validdata = TabularDataset( path=r\".../dialogs.tsv\",\n",
    "                                  format=\"tsv\",\n",
    "                                  fields=fields\n",
    "                                        ).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in traindata:\n",
    "    print(nlp(word.a).vector, nlp(word.q).vector.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = [[len(tr.q), len(tr.a), len(va.q), len(va.q)]for tr, va in zip(traindata, validdata)]\n",
    "max(np.array(length).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintensor, validtensor = BucketIterator.splits((traindata, validdata), batch_size=100, device=\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in traintensor.q:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, inpsize, hidden, eos):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(inpsize, hidden)\n",
    "        self.lstm = nn.LSTM(hidden, hidden)\n",
    "        self.hid = hidden\n",
    "        self.lstmcell = nn.LSTMCell(hidden, hidden)\n",
    "        self.eos = eos\n",
    "        \n",
    "    def forward(self, txt):\n",
    "        print(txt.size())\n",
    "        h0 = Variable(th.zeros((1, 100, self.hid)))\n",
    "        c0 = Variable(th.zeros((1, 100, self.hid)))\n",
    "        embed = self.embedding(txt)\n",
    "        output, (h, c) = self.lstm(embed, (h0, c0))\n",
    "        h = h[-1]\n",
    "        c = c[-1]\n",
    "        x =output[-1]\n",
    "        outputs = []\n",
    "        while x!=eos:\n",
    "            x, (h, c) = self.lstmcell(x, (h, c))\n",
    "            outputs.append(x)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewRNN(LightningModule):\n",
    "    def __init__(self,data, model, lr):\n",
    "        super(NewRNN, self).__init__()\n",
    "        self.model = model \n",
    "        self.data = data \n",
    "        self.lr = lr \n",
    "        self.loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, txt):\n",
    "        return self.model(txt)\n",
    "    \n",
    "    def training_step(self, batch, bth_idx):\n",
    "        question = batch.q \n",
    "        answer   = batch.a\n",
    "        ypred = self(question) \n",
    "        loss = self.loss(ypred, answer)\n",
    "        self.log(\"loss\", loss)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return Adam(self.model.parameters(), lr=self.lr)\n",
    "    \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(300, 300, eos=eos)\n",
    "learn = NewRNN(traintensor, model, lr=1e-4)\n",
    "trainer = Trainer(min_epochs=3, max_epochs=10, accelerator=\"mps\")\n",
    "trainer.fit(learn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
